{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall torch torchvision pytorch-lightning nni medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# We'll be adding a few data augmentations to the training loop\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  \n",
    "    transforms.ColorJitter(brightness=0.2), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5), # We're training on GrayScale images so we'll standardise to 0.5\n",
    "])\n",
    "\n",
    "\n",
    "val_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(.5, .5),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# MedMNIST datasets outputs label of [batch_size, num_classes] shape, so we reduce 1 dimension for the CrossEntropy Loss\n",
    "class CorrectDimensions(Dataset):\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        self.data = dataset(**kwargs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        return image, label.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from medmnist import PneumoniaMNIST, BreastMNIST\n",
    "\n",
    "# Wrap MedMNIST datasets with our dataset class\n",
    "pneu_train_data = CorrectDimensions(PneumoniaMNIST, split='train', transform=train_transformations, download=True)\n",
    "pneu_val_data = CorrectDimensions(PneumoniaMNIST, split='val', transform=val_transformations, download=True)\n",
    "pneu_test_data = CorrectDimensions(PneumoniaMNIST, split='test', transform=val_transformations, download=True)\n",
    "\n",
    "breast_train_data = CorrectDimensions(BreastMNIST, split='train', transform=train_transformations, download=True)\n",
    "breast_val_data = CorrectDimensions(BreastMNIST, split='val', transform=val_transformations, download=True)\n",
    "breast_test_data = CorrectDimensions(BreastMNIST, split='test', transform=val_transformations, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModelSpace(\n",
       "  (convolution_block): LayerChoice(\n",
       "    label='convolution_block'\n",
       "    (0): SimpleConvolutionBlock(\n",
       "      (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): BiggerKernelBlock(\n",
       "      (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): Depth3ConvolutionBlock(\n",
       "      (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): Depth4ConvolutionBlock(\n",
       "      (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (fc1): MutableLinear(in_features=6272, out_features=Categorical([64, 128], label='feature'))\n",
       "  (fc2): MutableLinear(in_features=Categorical([64, 128], label='feature'), out_features=2)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nni.nas.nn.pytorch import LayerChoice, ModelSpace, MutableLinear\n",
    "\n",
    "# This will be our most basic building block with just 2 convolutions and 1 pooling layer\n",
    "class SimpleConvolutionBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, 3, 1, 1) # 28x28\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 14x14\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1) # 32x14x14\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        output = self.conv2(self.pool(x))\n",
    "        return output\n",
    "    \n",
    "\n",
    "# We'll compare it with similar layer but a larger kernel for the first convolution layer\n",
    "# We'll be using padding of 2 to keep the same dimensions as DART expects them to be equal\n",
    "class BiggerKernelBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, 5, 1, 2) # 28x28\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 14x14\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1) # 32x14x14\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        output = self.conv2(self.pool(x))\n",
    "        return output\n",
    "\n",
    "# Similarly to Dart model space we'll also test depths of 3 and 4 for our convolutions\n",
    "class Depth3ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, 3, 1, 1) # 28x28\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 14x14\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1, 1) # 32x14x14\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        output = self.conv3(self.pool(x))\n",
    "        return output\n",
    "    \n",
    "# Following a standard practise we'll be increased the width of the network as the depth of the network increases\n",
    "# We'll reduce the width of the last convolution to match that of fully connected layers proceeding the block\n",
    "class Depth4ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, 3, 1, 1) # 28x28\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 14x14\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1) # 14x14\n",
    "        self.conv4 = nn.Conv2d(64, 32, 3, 1, 1) # 32x14x14\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        output = self.conv4(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class CNNModelSpace(ModelSpace):\n",
    "    def __init__(self, input_channels = 1,  num_classes = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convolution_block = LayerChoice([\n",
    "            SimpleConvolutionBlock(input_channels=input_channels),\n",
    "            BiggerKernelBlock(input_channels=input_channels),\n",
    "            Depth3ConvolutionBlock(input_channels=input_channels),\n",
    "            Depth4ConvolutionBlock(input_channels=input_channels)\n",
    "        ], label='convolution_block')\n",
    "\n",
    "        # Additionally we'll also test different widths of the fully connected layers\n",
    "        # Due to DartStrategy being one-shot we won't be using DropOut, instead we'll apply weight decay as regularization technique\n",
    "        feature = nni.choice('feature', [64, 128])\n",
    "        self.fc1 = MutableLinear(32*14*14, feature)\n",
    "        self.fc2 = MutableLinear(feature, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution_block(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        output = self.fc2(F.relu(self.fc1(x)))\n",
    "        return output # pl.Classification expects the output to be logits (not probabilties) so we won't be applying a Sigmoid\n",
    "    \n",
    "\n",
    "model_space = CNNModelSpace()\n",
    "model_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PneumoniaMNIST Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "from nni.nas.strategy import DARTS as DartsStrategy\n",
    "import nni.nas.strategy as strategy\n",
    "import nni.nas.evaluator.pytorch.lightning as pl\n",
    "\n",
    "# Initiate our model space to search through\n",
    "pneu_model_space = CNNModelSpace()\n",
    "\n",
    "# Initiate our search strategy\n",
    "pneu_search_strategy = DartsStrategy()\n",
    "\n",
    "# Initiate our evaluator\n",
    "pneu_evaluator = pl.Classification(\n",
    "  num_classes=2,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-4,\n",
    "  train_dataloaders=pl.DataLoader(pneu_train_data, batch_size=32),\n",
    "  val_dataloaders=pl.DataLoader(pneu_val_data, batch_size=32),\n",
    "  max_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:43:56] \u001B[32mConfig is not provided. Will try to infer.\u001B[0m\n",
      "[2024-03-06 11:43:56] \u001B[32mStrategy is found to be a one-shot strategy. Setting execution engine to \"sequential\" and format to \"raw\".\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from nni.nas.experiment import NasExperiment\n",
    "pneu_exp = NasExperiment(pneu_model_space, pneu_evaluator, pneu_search_strategy)\n",
    "\n",
    "pneu_exp.config.max_trial_number = 3   # for reasons of limited computing power we won't be doing more than 3 trials\n",
    "pneu_exp.config.trial_concurrency = 1  # will run 1 trial concurrently\n",
    "pneu_exp.config.trial_gpu_number = 0   # will not use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: Checkpoint callback does not have last_model_path or best_model_path attribute. Either the strategy has not started, or it did not save any checkpoint: <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f1a3539c3d0>\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[32mCheckpoint saved to /home/azureuser/nni-experiments/ap2ybetj/checkpoint.\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[32mExperiment initialized successfully. Starting exploration strategy...\u001B[0m\n",
      "[2024-03-06 11:44:00] \u001B[33mWARNING: Validation dataloaders are missing. Safe to ignore this warning when using one-shot strategy.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 11:44:06.928185: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-06 11:44:11.290363: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 11:44:14.829051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | training_module | ClassificationModule | 868 K \n",
      "---------------------------------------------------------\n",
      "868 K     Trainable params\n",
      "0         Non-trainable params\n",
      "868 K     Total params\n",
      "3.475     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd29e4379045433dba566478b8b91943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/transforms/functional.py:136: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:48:35] \u001B[32mWaiting for models submitted to engine to finish...\u001B[0m\n",
      "[2024-03-06 11:48:35] \u001B[32mExperiment is completed.\u001B[0m\n",
      "[2024-03-06 11:48:35] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pneu_exp.run(port = 8001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training the best model for PneumoniaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Pneumonia dataset:\n",
      " CNNModelSpace(\n",
      "  (convolution_block): SimpleConvolutionBlock(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pneu_model_dict = pneu_exp.export_top_models(formatter='dict')[0]\n",
    "\n",
    "pneu_best_model = CNNModelSpace().freeze(pneu_model_dict)\n",
    "\n",
    "print(f'Best model for Pneumonia dataset:\\n {pneu_best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | metrics   | ModuleDict       | 0     \n",
      "2 | _model    | CNNModelSpace    | 808 K \n",
      "-----------------------------------------------\n",
      "808 K     Trainable params\n",
      "0         Non-trainable params\n",
      "808 K     Total params\n",
      "3.232     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83020aaed1044e1dba8119a411c8015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8176606d99154793a0376eabeebba5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935d0c4df9da401cbdbca2a97bc4e488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:49:39] \u001B[32mIntermediate result: 0.9541984796524048  (Index 0)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2fcbf138104462ad0febc78d5d09a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:49:44] \u001B[32mIntermediate result: 0.9580152630805969  (Index 1)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35254239af9547d1bc19817d6008ad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:49:53] \u001B[32mIntermediate result: 0.9618320465087891  (Index 2)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9d6e303b4b4928a2d568a2d162de23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:01] \u001B[32mIntermediate result: 0.9618320465087891  (Index 3)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2322b206df14595bc85fe2c77c9e2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:07] \u001B[32mIntermediate result: 0.9580152630805969  (Index 4)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89a480179343f1872e80f4db033ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:13] \u001B[32mIntermediate result: 0.9599236845970154  (Index 5)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c5202269f14b3db1b75aa9f02c8b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:20] \u001B[32mIntermediate result: 0.9599236845970154  (Index 6)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2c5c62356845aeb9cd9745c681d87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:26] \u001B[32mIntermediate result: 0.9618320465087891  (Index 7)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b8317538dd4d869535c4de681bc32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:31] \u001B[32mIntermediate result: 0.9580152630805969  (Index 8)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232980ea53e948c094f1d9f47d9e5370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:37] \u001B[32mIntermediate result: 0.9751908183097839  (Index 9)\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:38] \u001B[32mFinal result: 0.9751908183097839\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pneu_evaluator = pl.Classification(\n",
    "  num_classes=2,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-4,\n",
    "  train_dataloaders=pl.DataLoader(pneu_train_data, batch_size=32),\n",
    "  val_dataloaders=pl.DataLoader(pneu_val_data, batch_size=32),\n",
    "  max_epochs=10,\n",
    ")\n",
    "\n",
    "pneu_evaluator.fit(pneu_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# BreastMNIST Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initiate our model space to search through\n",
    "breast_model_space = CNNModelSpace()\n",
    "\n",
    "# Initiate our search strategy\n",
    "breast_search_strategy = DartsStrategy()\n",
    "\n",
    "# Initiate our evaluator\n",
    "breast_evaluator = pl.Classification(\n",
    "  num_classes=2,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-5,\n",
    "  train_dataloaders=pl.DataLoader(breast_train_data, batch_size=32, shuffle=True),\n",
    "  val_dataloaders=pl.DataLoader(breast_val_data, batch_size=32, shuffle=True),\n",
    "  max_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:51] \u001B[32mConfig is not provided. Will try to infer.\u001B[0m\n",
      "[2024-03-06 11:50:51] \u001B[32mStrategy is found to be a one-shot strategy. Setting execution engine to \"sequential\" and format to \"raw\".\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "breast_exp = NasExperiment(breast_model_space, breast_evaluator, breast_search_strategy)\n",
    "\n",
    "breast_exp.config.max_trial_number = 3   # spawn 3 trials at most\n",
    "breast_exp.config.trial_concurrency = 1  # will run 1 trial concurrently\n",
    "breast_exp.config.trial_gpu_number = 0   # will not use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: Checkpoint callback does not have last_model_path or best_model_path attribute. Either the strategy has not started, or it did not save any checkpoint: <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f19eba90e20>\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[32mCheckpoint saved to /home/azureuser/nni-experiments/pvnwa492/checkpoint.\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[32mExperiment initialized successfully. Starting exploration strategy...\u001B[0m\n",
      "[2024-03-06 11:50:53] \u001B[33mWARNING: Validation dataloaders are missing. Safe to ignore this warning when using one-shot strategy.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | training_module | ClassificationModule | 868 K \n",
      "---------------------------------------------------------\n",
      "868 K     Trainable params\n",
      "0         Non-trainable params\n",
      "868 K     Total params\n",
      "3.475     Total estimated model params size (MB)\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aa2df08ff44326b81363a6d999c0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:21] \u001B[32mWaiting for models submitted to engine to finish...\u001B[0m\n",
      "[2024-03-06 11:51:21] \u001B[32mExperiment is completed.\u001B[0m\n",
      "[2024-03-06 11:51:21] \u001B[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_exp.run(port = 8001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Breast dataset:\n",
      " CNNModelSpace(\n",
      "  (convolution_block): SimpleConvolutionBlock(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "breast_model_dict = breast_exp.export_top_models(formatter='dict')[0]\n",
    "\n",
    "breast_best_model = CNNModelSpace().freeze(breast_model_dict)\n",
    "\n",
    "print(f'Best model for Breast dataset:\\n {breast_best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | metrics   | ModuleDict       | 0     \n",
      "2 | _model    | CNNModelSpace    | 808 K \n",
      "-----------------------------------------------\n",
      "808 K     Trainable params\n",
      "0         Non-trainable params\n",
      "808 K     Total params\n",
      "3.232     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91be48a082b14e60a26f0b3b4312a47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797c8c457734400fbc72607afcb7f9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0392df5dda444cbab6735e27881bd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:54] \u001B[32mIntermediate result: 0.7307692170143127  (Index 10)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e2f0d03624d43b9c15a9b0ca9f1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:55] \u001B[32mIntermediate result: 0.8205128312110901  (Index 11)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c0f9b50a3b4b1f9853c8876608216a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:57] \u001B[32mIntermediate result: 0.7564102411270142  (Index 12)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4653801ddc44e9828408d3110ef31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:58] \u001B[32mIntermediate result: 0.7692307829856873  (Index 13)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d2535da7b5404fb408bd5a30e7b247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:51:59] \u001B[32mIntermediate result: 0.8205128312110901  (Index 14)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25df72b34aef43deb623667b0acad9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:00] \u001B[32mIntermediate result: 0.807692289352417  (Index 15)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f7906e3f634825ad50bde72a3fc6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:01] \u001B[32mIntermediate result: 0.807692289352417  (Index 16)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0619dd830f114cdcb33c6d89fc8692bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:02] \u001B[32mIntermediate result: 0.7435897588729858  (Index 17)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccabfa86f614c8d904e1b636b0c9d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:03] \u001B[32mIntermediate result: 0.807692289352417  (Index 18)\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77192521ad1c467d8fc1fa4d14f87a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:04] \u001B[32mIntermediate result: 0.8589743375778198  (Index 19)\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 11:52:04] \u001B[32mFinal result: 0.8589743375778198\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "breast_evaluator = pl.Classification(\n",
    "  num_classes=2,\n",
    "  learning_rate=1e-3,\n",
    "  weight_decay=1e-5,\n",
    "  train_dataloaders=pl.DataLoader(breast_train_data, batch_size=32, shuffle=True),\n",
    "  val_dataloaders=pl.DataLoader(breast_val_data, batch_size=32, shuffle=True),\n",
    "  max_epochs=10,\n",
    ")\n",
    "\n",
    "breast_evaluator.fit(breast_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analysing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pneu_test_dataloader = torch.utils.data.DataLoader(pneu_test_data, batch_size = len(pneu_test_data), shuffle = False)\n",
    "breast_test_dataloader = torch.utils.data.DataLoader(breast_test_data, batch_size = len(breast_test_data), shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs\n",
    "            labels = labels\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1).numpy() # Converting probabilities to 1's and 0's\n",
    "            probs = torch.sigmoid(outputs)[:, 1].numpy() # Convert logits to probabilities\n",
    "            \n",
    "            all_probabilities.extend(probs)\n",
    "            all_preds.extend(predictions)\n",
    "            all_targets.extend(labels.numpy())\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    auc_roc = roc_auc_score(all_targets, all_probabilities)  # Use probabilities of the positive class\n",
    "    \n",
    "    return accuracy, auc_roc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia Model - Test Accuracy: 0.8510, Test AUC-ROC: 0.9340\n",
      "Breast Cancer Model - Test Accuracy: 0.8013, Test AUC-ROC: 0.8283\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Pneumonia model on the test set\n",
    "pneu_accuracy, pneu_auc_roc = evaluate_model(pneu_best_model, pneu_test_dataloader)\n",
    "print(f\"Pneumonia Model - Test Accuracy: {pneu_accuracy:.4f}, Test AUC-ROC: {pneu_auc_roc:.4f}\")\n",
    "\n",
    "# Evaluate Breast Cancer model on the test set\n",
    "breast_accuracy, breast_auc_roc = evaluate_model(breast_best_model, breast_test_dataloader)\n",
    "print(f\"Breast Cancer Model - Test Accuracy: {breast_accuracy:.4f}, Test AUC-ROC: {breast_auc_roc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}